{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 机器学习分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 根据标签分为：\n",
    "    * 监督学习：数据的所有标签都知道\n",
    "    * 半监督学习：知道一部分数据的标签\n",
    "    * 无监督学习：不知道标签\n",
    "    * 强化学习：对好的结果给予激励，对不好的结果给予惩罚，不断调整模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 根据不同协议分为：\n",
    "    * Batch学习：数据的输入是一批的。\n",
    "    * 在线学习：数据是实时更新，不断优化模型。\n",
    "    * 主动学习：具备主动问问题的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入数据分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* concrete features：具体特征\n",
    "* raw features：如图像像素\n",
    "* abstract features：抽象特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 机器学习必须满足的条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 假设空间H的size M是有限的，即当N足够大的时候，那么对于假设空间中任意一个假设g，$E_{in}=E_{out}$。\n",
    "* 利用算法A从假设空间H中，挑选一个g，$E_{in}(g)=0, E_{out}=0$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在训练集上的叫做训练（经验）误差，新样本上叫做泛化误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 过拟合是无法避免的，只能缓解或者减小风险。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据集划分方法：留出法，交叉验证法，自助法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 评价指标：错误率，精度，查全率，查准率，F1\n",
    "$$\n",
    "F1 = \\frac{2\\cdot TP}{样本总数+TP-TN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC曲线横轴是假正例率，纵轴是真正例率。若一个学习器的ROC曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者。ROC曲线下的面积称为AUC。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 偏差；度量学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力；\n",
    "* 方差：度量同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响；\n",
    "* 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sigmoid函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = \\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对数几率回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = \\frac{1}{1+e^{-(w^Tx+b)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用对数函数来代替阶跃函数\n",
    "\n",
    "![image.png](attachment:9ad7586d-53dc-4f16-b540-9fd41e604161.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多分类学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将多分类拆分为多个二分类，拆解方式有：\n",
    "    * 一对一：两两组合，将其中一个类看作是正类，一个类看作负类，多个分类器的结果进行组合，需要训练$N(N-1)/2$个分类器。\n",
    "    * 一对多：一个类看作正类，其余类看作负类，需要训练N个分类器。\n",
    "    * 多对多：每次将若干个类作为正类，若干个类作为负类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 类别不平衡\n",
    "* 在类别不平衡时，有三类做法：\n",
    "    * 对反类样例进行欠采样，去除一些反样例，使得正反样例接近。\n",
    "    * 对正类样例进行过采样，增加一些正样例，使它们接近。\n",
    "    * 直接基于原始训练集进行学习，但是用训练好的分类器进行预测时，将$\\frac{y}{1-y} \\cdot \\frac{m^-}{m^+}$嵌入到决策过程中，称为阈值移动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 决策树的生成是一个递归的过程，有三种情况会导致递归返回：\n",
    "    * 当前节点包含的样本全属于同一类别，无需划分；\n",
    "    * 当前属性集为空，或所有样本在所有属性上取值相同，无法划分；\n",
    "    * 当前结点包含的样本集合为空，不能划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 划分选择：\n",
    "    * 信息熵是度量样本集合纯度最常用的指标。$Ent(D) = -\\sum_{k=1}^{|y|}p_k log_2p_k$，$Ent(D)$值越小，D的纯度越高。\n",
    "    * 信息增益$Gain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)$，信息增益越大，意味着使用属性a来进行划分所获得的纯度提升最大。\n",
    "    * 增益率：$Gain_ratio(D, a)=\\frac{Gain(D,a)}{IV(a)}$，其中$IV(a)=-\\sum_{v=1}^{V}\\frac{|D^v|}{|D|}log_2 \\frac{|D^v|}{|D|}$选择最优划分属性。属性a的可能取值（V）数目越多，则IV的值就越大。\n",
    "    * 基尼指数：$Gini\\_index(D,a)=\\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Gini(D^v)$，基尼指数越小，D的纯度越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **ID3**采用信息增益进行属性划分。\n",
    "* **C4.5**先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率增益率最高的进行属性划分。\n",
    "* **CART决策树**使用基尼指数选择划分属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 剪枝处理\n",
    "    * 决策树剪枝的基本策略有“预剪枝”和“后剪枝”。\n",
    "        * 预剪枝：在决策树生成过程中，对每个结点在划前先进行估计，若当前结点的划分不能带来决策树泛化性能的提升，则停止划分并将当前结点标记为叶结点；\n",
    "        * 后剪枝：先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 由两层神经元组成，输出层与输入层之间的一层神经元称为隐含层，隐含层和输出层神经元都是拥有激活函数的功能神经元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 缓解BP网络的过拟合：\n",
    "    * 早停：将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练。同时返回具有最小验证集误差的连接权和阈值。\n",
    "    * 正则化：在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。仍令$E_k$表示第k个训练样例上的误差，$w_i$表示连接权和阈值，则误差目标函数为$E = \\lambda\\frac{1}{m}\\sum_{k=1}^{m}E_k+(1-\\lambda)\\sum_{i}w_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解决过拟合问题：\n",
    "* 收集更多的数据\n",
    "* 通过正则化引入对复杂度的惩罚\n",
    "* 选择更少参数的简单模型\n",
    "* 对数据降维（特征选择、特征抽取）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征选择的一般过程：\n",
    "* 生成子集：搜索特征子集，为评价函数提供特征子集\n",
    "* 评价函数：评价特征子集的好坏\n",
    "* 停止准则：与评价函数相关，一般是阈值，评价函数达到一定标准后就可停止搜索\n",
    "* 验证过程：在验证数据集上验证选出来的特征子集的有效性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据特征选择的形式，分为三大类：\n",
    "* Filter(过滤法)：按照散发性或相关性对各个特征进行评分，设定阈值或选择特征的个数进行筛选。\n",
    "    * 使用以下方法度量每个特征的评分\n",
    "        * Pearson相关系数\n",
    "            * 只对线性关系敏感，如果是非线性的，相关性可能会接近0\n",
    "        * 卡方验证\n",
    "        * 互信息和最大信息系数\n",
    "            * 互信息不属于度量方式，没法归一化，在不同数据上的结果无法比较，对连续变量的计算不是很方便。\n",
    "            * 最大信息系数，寻找最优的离散化方式，把互信息取值转换成一种度量方式。\n",
    "        * 距离相关系数\n",
    "            * 距离相关系数是0，那么可以说这两个变量是独立的。\n",
    "        * 方差选择法\n",
    "            * 计算各个特征的方差，根据阈值，选择方差大于阈值的特征\n",
    "* Wrapper(包装法)：根据目标函数，每次选择若干特征，或者排除若干特征。\n",
    "    * 对于每一个待选的特征子集，都在训练集上训练一遍模型，然后在测试集上根据误差大小选择除特征子集。\n",
    "        * 前向搜索：每次增量的从剩余未选中的特征选出一个加入特征集中，待达到阈值或n时，从所有的F中选出错误率最小的。\n",
    "        * 后向搜索：将F设置为n，然后每次删除一个特征，并评价，直到达到阈值或者为空，然后选择最佳的F。\n",
    "        * 递归特征消除法：使用一个基模型来进行多轮训练，每轮训练后通过学习器返回的coef_或feature_importances_消除若干权值较低的特征，再基于新的特征集进行下一轮训练。\n",
    "* Embedded(嵌入法)：先使用某些机器学习的模型进行训练，得到各特征的权值系数，根据系数从大到小选择特征。\n",
    "    * 基于惩罚项的特性选择法，通过L1正则化项来选择特征：L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性。\n",
    "    * 基于学习模型的特征排序：这种方法的思路是直接使用你要用的机器学习算法，针对每个单独的特征和响应变量建立预测模型。假如某个特征和响应变量之间的关系是非线性的，可以用基于树的方法、或扩展的线性模型等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 监督学习、半监督学习、无监督学习的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 它的训练数据是有标签的，训练目标是能够给新数据以正确的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 经典算法：SVM、线性判别、决策树、朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 半监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 试图对未识别数据进行建模，在此基础上再对标识的数据进行预测。数据的分布不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，可以得到好的分类效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 经典算法：半监督SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 常常被用于数据挖掘，用于在大量无标签数据中发现什么。它的训练数据是无标签的，训练目标是能对观察值进行分类或区分。使用的是没有标签的数据，机器会主动学习数据的特征，并将它们分为若干类别，相当于形成未知的标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 经典算法：ｋ-means，主成分分析PAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 半监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 半监督学习算法可分为：自训练算法，基于图的半监督算法，半监督SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 简单自训练\n",
    "* 用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签，或软标签，挑选分类正确的无标签样本，把挑出来的无标签样本用来训练分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 协同训练\n",
    "* 也是自训练的一种，假设每个数据可以从不同角度分类，不同角度可以训练除不同的分类器，然后用这些不同角度训练出来的分类器对无标签样本进行分类，再挑选出认为可信的无标签样本加入训练集中。由于这些分类器从不同角度训练出来的，可以形成一种互补，提高分类精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 半监督字典学习\n",
    "* 也是自训练的一种，先是用有标签数据作为字典，对无标签数据进行分类，挑选出认为分类正确的无标签样本，加入字典中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 标签传播算法\n",
    "* 是一种基于图的半监督算法，通过构造图结构来寻找训练数据中有标签数据和无标签数据的关系。这是一种直推式的半监督算法，即只对训练集中的无标签数据进行分类，标签传播的过程，会流经无标签数据，即有些无标签数据的标签的信息，是从另一些无标签数据中流过来的，用到了无标签数据之间的联系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 半监督SVM\n",
    "* 监督SVM利用了结构风险最小化来分类的，半监督SVM用上了无标签数据的空间分布信息，即决策超平面应该与无标签数据的分布一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 半监督深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.无标签数据预训练，有标签数据微调\n",
    "* 无监督预训练\n",
    "    * 一是用所有数据逐层重构预训练，对网络的每一层，都做重构自编码，得到参数后用有标签数据微调；二是用所有数据训练重构自编码网络，然后把自编码网络的参数，作为初始参数，用有标签数据微调。\n",
    "* 伪有监督预训练\n",
    "    * 通过某种方式/算法，给无标签数据附上伪标签信息，先用这些伪标签信息来预训练网络，然后在用有标签数据来微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.利用从网络得到的深度特征做半监督算法\n",
    "* 先用有标签数据训练网络，从该网络中提取所有数据的特征，以这些特征来用某种分类算法对无标签数据进行分类，挑选认为分类正确的无标签数据加入到训练集，再训练网络，如此循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.让网络work in semi-supervised fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 是学习做什么才能使得数值化的收益信号最大化。开发已有的经验来获取收益，同时也要进行试探，使得未来可以获得更好的动作选择空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在强化学习中，有两个可以进行交互的对象：智能体和环境。\n",
    "    * 智能体：可以感知环境的状态，并根据反馈的奖励学习选择一个合适的动作，来最大化长期总收益。\n",
    "    * 环境：环境会接受智能体执行的一系列动作，对这一系列动作进行评价并转换为一种可量化的信号反馈给智能体。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 强化学习有四个核心要素：策略，回报函数、价值函数和环境模型。\n",
    "    * 策略：定义了智能体在特定时间的行为方式。策略是环境状态到动作的映射。\n",
    "    * 回报函数：定义了强化学习问题中的目标。在每一步中，环境向智能体发送一个称为收益的标量数值。\n",
    "    * 价值函数：表示了从长远的角度看什么是好的。一个状态的价值是一个智能体从这个状态开始，对将来累积的总收益的期望。\n",
    "    * 环境模型：是一种对环境的反应模式的模拟，它允许对外部环境的行为进行推断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 强化学习是一种对目标导向的学习与决策问题进行理解和自动化处理的计算方法。它强调智能体通过与环境的直接互动来学习，而不需要可效仿的监督信号或对周围环境的完全建模，因而与其他的计算方法相比具有不同的范式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 强化学习使用马尔可夫决策过程的形式化框架，使用状态，动作和收益定义学习型智能体与环境的互动过程。这个框架力图简单地表示人工智能问题的若干重要特征，这些特征包含了对因果关系的认知，对不确定性的认知，以及对显式目标存在性的认知。\n",
    "* 价值与价值函数是强化学习方法的重要特征，价值函数对于策略空间的有效搜索来说十分重要。相比于进化方法以对完整策略的反复评估为引导对策略空间进行直接搜索，使用价值函数是强化学习方法与进化方法的不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 应用\n",
    "* 游戏\n",
    "* 广告和推荐\n",
    "* 对话系统\n",
    "* 机器人"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
