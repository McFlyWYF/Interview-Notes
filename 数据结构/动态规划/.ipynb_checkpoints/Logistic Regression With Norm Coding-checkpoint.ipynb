{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homewrok Coding: Logistic Regression.\n",
    "#### Please export this jupyter notebook as PDF, and hand in .pdf file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part of homework, you need to implement Logistic Regression using Python in this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "data = load_breast_cancer().data\n",
    "target = load_breast_cancer().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([212, 357], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Some helper functions are given below, you are free to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict y of x with current weights\n",
    "def predict(x,w):\n",
    "    y_pred=[]\n",
    "    for i in range(len(x)):\n",
    "        y = (np.asscalar(1/(1+np.exp(-(np.dot(w,x[i]))))))\n",
    "        if y<0.5:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calulate TPR,FPR,TNR and FNR to be included in confusion matrix\n",
    "def find_rates(mat):\n",
    "    mat2=[]\n",
    "    mat2.append((mat[0,0]))\n",
    "    mat2.append((mat[1,0]))\n",
    "    mat2.append((mat[0,1]))\n",
    "    mat2.append((mat[1,1]))\n",
    "    mat2=np.reshape(mat2,(2,2))\n",
    "    mat2 = pd.DataFrame(mat2,columns=[0,1],index=[0,1])\n",
    "    mat2.index.name = 'Predicted'\n",
    "    mat2.columns.name = 'Actual'\n",
    "    return mat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implement Logistic Regression using sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Implementation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression using sklearn\n",
    "LRclf = LogisticRegression(penalty = 'l2', C=0.1, solver = 'liblinear')\n",
    "LRclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = LRclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 67, 121], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 67, 121], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_sklearn,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 1, 1, 120)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_sklearn).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Confusion Matrix for test data using sklearn Logistic Regression'}, xlabel='Actual', ylabel='Predicted'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_test = find_rates(confusion_matrix(y_test, y_pred_sklearn))\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.title('Confusion Matrix for test data using sklearn Logistic Regression')\n",
    "sns.heatmap(mat_test,annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893617021276596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try different solvers and parameters. Answer these questions below:\n",
    "#### 1. Explain the parameters and their effects in LogisticRegression()\n",
    "#### 2. Is it feasible to set parameters 'penalty' and 'solver' to (penalty = 'l1', solver = 'newton-cg')? If not, briefly explain why (you don't have to do any mathematical derivation).\n",
    "#### Hints: you can read official document from \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#0000dd\">My Answer:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explain the parameters and their effects in LogisticRegression()\n",
    "\n",
    "#### i) penalty = 'l2'\n",
    "\n",
    "- **penalty** has the following parameters: {'l1', 'l2', 'elasticnet', 'none'} with default = 'l2'.\n",
    "\n",
    "    It specifies the norm of the penalty:\n",
    "\n",
    "    - `none`: no penalty is added;\n",
    "    - `l2`: add a L2 penalty term and it is the default choice; \n",
    "    - `l1`: add a L1 penalty term;\n",
    "    - `elasticnet`: both L1 and L2 penalty terms are added.\n",
    "\n",
    "    Here in Part1, it chooses the $l_2$ regularization.\n",
    "\n",
    "#### ii) C = 0.1\n",
    "\n",
    "&emsp; **C** is float with default = 1.0.\n",
    "\n",
    "&emsp; It is the inverse of regularization strength and must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "\n",
    "&emsp; Here in Part1, it chooses the $C = 0.1$, implying the regularization strength is $10$.\n",
    "\n",
    "#### iii) solver = 'liblinear'\n",
    "\n",
    "- **solver** has the following parameters: {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'} with default='lbfgs'.\n",
    "\n",
    "    It denotes the algorithm to use in the optimization problem. Default is 'lbfgs'. To choose a solver, you might want to consider the following aspects:\n",
    "\n",
    "    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones;\n",
    "    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss;\n",
    "    - 'liblinear' is limited to one-versus-rest schemes.\n",
    "    \n",
    "    Here in Part1, it chooses 'liblinear' which uses a coordinate descent (CD) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Is it feasible to set parameters 'penalty' and 'solver' to (penalty = 'l1', solver = 'newton-cg')? If not, briefly explain why (you don't have to do any mathematical derivation).\n",
    "\n",
    "- No. Because this optimization algorithm requires the first-order or second-order continuous derivatives of the loss function. It can not be used for L1 regularization without continuous derivatives, but can only be used for L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement Logistic Regression without using its library. In other words, you need to implement logistic regression by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part, the hyper parameters are given, do not change them. \n",
    "# Note that the Logistic regression in this part has regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Implement logistic regression using Batch-GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At each iteration, train all the samples and update weights.\n",
    "\"\"\"\n",
    "n_iter=50  # number of iterations\n",
    "reg=0.01   # regularization parameter lambda\n",
    "r=0.1      # learning rate\n",
    "sample_size=X_train.shape[0]    # batch size for BGD\n",
    "N=X_train.shape[0]\n",
    "\n",
    "\n",
    "for j in range(n_iter):\n",
    "    #Your codes below:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting predictions for test datapoints\n",
    "y_pred_BGD = predict(X_test,w_BGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_BGD,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw confusion matrix\n",
    "mat_test = find_rates(confusion_matrix(y_test, y_pred_BGD))\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.title('Confusion Matrix for test data using BGD Logistic Regression')\n",
    "sns.heatmap(mat_test,annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Implement logistic regression using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this part, you need to implement logistic regression using SGD method. \n",
    "At each iteration, choose 20 samples randomly and compute dJ(theta)/d(theta) among \n",
    "those 20 samples then update the vector of weights.\n",
    "\n",
    "***Note that the random seed at each iteration is given, do NOT modify it!!!***\n",
    "\"\"\"\n",
    "n_iter=50  # number of iterations\n",
    "reg=0.01   # regularization parameter lambda\n",
    "r=0.1      # learning rate\n",
    "sample_size=20    # sample size for SGD\n",
    "N=X_train.shape[0]\n",
    "\n",
    "for j in range(n_iter):\n",
    "    np.random.seed(j) \n",
    "    idx=np.random.randint(X_train.shape[0],size=sample_size) \n",
    "    # Do NOT modify codes above, especially the random code.\n",
    "    # At each iterations, choose samples from X_train, y_train, with index idx.\n",
    "    # Your codes below:\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting predictions for test datapoints\n",
    "y_pred_SGD = predict(X_test,w_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_SGD,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw confusion matrix\n",
    "mat_test = find_rates(confusion_matrix(y_test, y_pred_SGD))\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.title('Confusion Matrix for test data using SGD Logistic Regression')\n",
    "sns.heatmap(mat_test,annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print a table to show every coefficients in vector w, \n",
    "and compute the absolute difference between coefficients of BGD and SGD methods.\n",
    "\"\"\"\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "p = PrettyTable()\n",
    "p.title='Weights from both models'\n",
    "p.field_names=['SKlearn','BGD', 'SGD', 'Difference']\n",
    "\n",
    "# You can rewrite codes below\n",
    "# Please remain five decimal places\n",
    "for i in range(30):\n",
    "    p.add_row(['{:.5f}'.format(LRclf.coef_[0,i]),'{:.5f}'.format(w_BGD[i]), \n",
    "               '{:.5f}'.format(w_SGD[i]), '{:.5f}'.format(abs(w_BGD[i]-w_SGD[i]))])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Given hyperparameters and random seeds, the w obtained by BGD and SGD should be unique. \n",
    "# In fact, the answer has been shown to you, if yours are not the same with the answer, score will be penalized.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}